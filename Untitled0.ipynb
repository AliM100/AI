{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRNzzRKax3rvfUj706/5Ii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allll-dev/AI/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "6pTjXKqlwyRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "dqFipgjDHcPO",
        "outputId": "b55e58f9-9a6c-4ae8-8843-aa874deb9611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow dependecies - functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer,Conv2D,Dense,MaxPooling2D,Input,Flatten\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "-S6jDzfswyl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set gpu Growth \n",
        "#Avoid OOM errors by setting GPU Memory Condumption Growth \n",
        "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu,True)"
      ],
      "metadata": {
        "id": "5le-bMAVwz8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create folder structure \n",
        "POS_PATH=os.path.join('data','positive')\n",
        "NEG_PATH=os.path.join('data','negative')\n",
        "ANC_PATH=os.path.join('data','anchor')"
      ],
      "metadata": {
        "id": "R5-pW80cw11T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(gpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx0FfIyQw3YJ",
        "outputId": "79a98dcf-ee2c-4f81-a3a9-772ac65531b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make directories \n",
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)"
      ],
      "metadata": {
        "id": "yt7Y2ADow6yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uncompress Tar GZ Labelled Faces in the Wild DataSet \n",
        "!tar -xf lfw.tgz"
      ],
      "metadata": {
        "id": "XkSrplOyKeZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move LFW Images to the following  repository data/negative\n",
        "for directory in os.listdir('lfw'):\n",
        "    for file in os.listdir(os.path.join('lfw',directory)):\n",
        "        EX_PATH=os.path.join('lfw',directory,file)\n",
        "        NEW_PATH=os.path.join(NEG_PATH,file)\n",
        "        os.replace(EX_PATH,NEW_PATH)"
      ],
      "metadata": {
        "id": "dIHNFhCMKgph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import uuid lib to generate unique image names\n",
        "import uuid"
      ],
      "metadata": {
        "id": "Z8MnqCWsMrxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uuid.uuid1()"
      ],
      "metadata": {
        "id": "6_PzguVkMt59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Establish a connection to the webcam\n",
        "cap=cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret,frame=cap.read()\n",
        "    frame=frame[120:120+250,200:200+250,:]\n",
        "    #collect anchors\n",
        "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
        "        #create the unique file path \n",
        "        imgname=os.path.join(ANC_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
        "       #write out anchor\n",
        "        cv2.imwrite(imgname,frame)\n",
        "        \n",
        "    #collect positives\n",
        "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
        "         #create the unique file path \n",
        "        imgname=os.path.join(POS_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
        "       #write out anchor\n",
        "        cv2.imwrite(imgname,frame)\n",
        "        \n",
        "    #Show image back to screen\n",
        "    cv2.imshow('Image Collection',frame)\n",
        "    #Breaking gracefully\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "#Release the webcam \n",
        "cap.release()\n",
        "#Close the image show frame\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "3QsTa0pxMvGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor=tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
        "positive=tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
        "negative=tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)"
      ],
      "metadata": {
        "id": "C3x8r-ThMwLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_test=anchor.as_numpy_iterator()\n"
      ],
      "metadata": {
        "id": "Yq8Zt0TbMxSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path):\n",
        "    #read image from file path\n",
        "    byte_img=tf.io.read_file(file_path)\n",
        "    img=tf.io.decode_jpeg(byte_img)\n",
        "    img=tf.image.resize(img,(100,100))\n",
        "    img=img/255.0\n",
        "    return img"
      ],
      "metadata": {
        "id": "wUa6xuhVMzMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.map(preprocess)"
      ],
      "metadata": {
        "id": "354XMYysM1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create Labelled Dataset\n",
        "#(anchor,positive)=>1,1,1,1,1\n",
        "#(anchor,negative)=>0,0,0,0,0"
      ],
      "metadata": {
        "id": "VmnOESD5M2HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data=positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "FjJfLmRaM3TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "Fo0d8R5vM4Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example=samples.next()"
      ],
      "metadata": {
        "id": "vI-5FdFMM5On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #build train and test partition\n",
        "def preprocess_twin(input_img,validation_img,label):\n",
        "    return(preprocess(input_img),preprocess(validation_img),label)"
      ],
      "metadata": {
        "id": "VESoJFLqM6Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=preprocess_twin(*example)"
      ],
      "metadata": {
        "id": "xSPYKfXoM7c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataloader pipline\n",
        "data=data.map(preprocess_twin)\n",
        "data=data.cache() \n",
        "data=data.shuffle(buffer_size=1024)"
      ],
      "metadata": {
        "id": "KaXPwE7uM83V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  samples=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "lW_WrTB9M9xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples.next()"
      ],
      "metadata": {
        "id": "65tV-X-6M-rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training partition\n",
        "train_data=data.take(round(len(data)*.7))\n",
        "train_data=train_data.batch(16)\n",
        "train_data=train_data.prefetch(8)\n"
      ],
      "metadata": {
        "id": "znRcdohnNAJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples=train_data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "z-Fi1DLQNA-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample=train_samples.next()"
      ],
      "metadata": {
        "id": "6fx7ICTrNCO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing partition\n",
        "test_data=data.skip(round(len(data)*.7))\n",
        "test_data=test_data.take(round(len(data)*.3))\n",
        "test_data=test_data.batch(16)\n",
        "test_data=test_data.prefetch(8)"
      ],
      "metadata": {
        "id": "PnvTpordNDCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build embedded layer \n",
        "def make_embedding():\n",
        "    inp=Input(shape=(100,100,3),name='input_image')\n",
        "    #First block\n",
        "    c1=Conv2D(64,(10,10),activation='relu')(inp)\n",
        "    m1=MaxPooling2D(64,(2,2),padding='same')(c1)\n",
        "    \n",
        "    #Second block\n",
        "    c2=Conv2D(128,(7,7),activation='relu')(m1)\n",
        "    m2=MaxPooling2D(64,(2,2),padding='same')(c2)\n",
        "    \n",
        "    #third block\n",
        "    c3=Conv2D(128,(4,4),activation='relu')(m2)\n",
        "    m3=MaxPooling2D(64,(2,2),padding='same')(c3)\n",
        "    \n",
        "    #final embedding block\n",
        "    c4=Conv2D(256,(4,4),activation='relu')(m3)\n",
        "    f1=Flatten()(c4)\n",
        "    d1=Dense(4096,activation='sigmoid')(f1)\n",
        "    return Model(inputs=[inp],outputs=[d1],name='embedding')"
      ],
      "metadata": {
        "id": "9I1kGIlJND_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=make_embedding()"
      ],
      "metadata": {
        "id": "HWwY_YhCNFdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.summary()"
      ],
      "metadata": {
        "id": "iR0p-NmANGf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build distance layer\n",
        "class L1Dist(Layer):\n",
        "    #Init method - inheritance\n",
        "     def __init__(self,**kwargs):\n",
        "            super().__init__()\n",
        "            \n",
        "     #Magic happens here - similarity calc\n",
        "     def call(self,input_embedding,validation_embedding):\n",
        "        return tf.math.abs(input_embedding-validation_embedding)"
      ],
      "metadata": {
        "id": "Uj6tZAL1NHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make Siamese Model \n",
        "def make_siamese_model():\n",
        "    \n",
        "    #Anchor image input in the network\n",
        "    input_image=Input(name='input_img',shape=(100,100,3))\n",
        "    \n",
        "    #Validation image input in the network\n",
        "    validation_image=Input(name='validation_image',shape=(100,100,3))\n",
        "    \n",
        "    #combine siamese distance components\n",
        "    siamese_layer=L1Dist()\n",
        "    siamese_layer._name='distance'\n",
        "    distances=siamese_layer(embedding(input_image),embedding(validation_image))\n",
        "     #classification layer\n",
        "    classifier=Dense(1,activation='sigmoid')(distances)\n",
        "    return Model([input_image,validation_image],outputs=classifier,name='SiameseNetwork')"
      ],
      "metadata": {
        "id": "J44YcEfQNIqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model=make_siamese_model()"
      ],
      "metadata": {
        "id": "5DP0ur_nNJyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training \n",
        "#setup loss and optimizer\n",
        "binary_cross_loss=tf.losses.BinaryCrossentropy()   "
      ],
      "metadata": {
        "id": "N3QhOzpYNK6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt=tf.keras.optimizers.Adam(1e-4)#0.0001"
      ],
      "metadata": {
        "id": "Y0dbpDTYNL1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Establish checkpoints\n",
        "checkpoint_dir='./training_checkpoints'\n",
        "checkpoint_prefix=os.path.join(checkpoint_dir,'ckpt')\n",
        "checkpoint=tf.train.Checkpoint(opt=opt,siamese_model=siamese_model)"
      ],
      "metadata": {
        "id": "cJ1sXi5CNMoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Build train step function\n",
        "@tf.function\n",
        "def train_step(batch):\n",
        "    #Record all of our operations\n",
        "    with tf.GradientTape() as tape:\n",
        "        #Get anchor and positive/negative image\n",
        "        X=batch[:2]\n",
        "        #Get label\n",
        "        y=batch[2]\n",
        "        #Forward pass\n",
        "        yhat=siamese_model(X,training=True)\n",
        "        #Calculate loss\n",
        "        loss=binary_cross_loss(y,yhat)\n",
        "    #Calculate gradients\n",
        "    grad=tape.gradient(loss,siamese_model.trainable_variables)\n",
        "        \n",
        "    #Calculate updated weights and apply to siamese model\n",
        "    opt.apply_gradients(zip(grad,siamese_model.trainable_variables))\n",
        "    \n",
        "    return loss    "
      ],
      "metadata": {
        "id": "jZFx6K60NNbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build training loop\n",
        "def train(data,EPOCHS):\n",
        "    #loop through epochs\n",
        "    for epoch in range(1,EPOCHS+1):\n",
        "        print('\\n EPOCH {}/{}'.format(epoch,EPOCHS))\n",
        "        progbar=tf.keras.utils.Progbar(len(data))\n",
        "        \n",
        "        #loop through each batch\n",
        "        for idx,batch in enumerate(data):\n",
        "            #Run train step here\n",
        "            train_step(batch)\n",
        "            progbar.update(idx+1)\n",
        "            \n",
        "         #Save checkpoints\n",
        "        if epoch%10==0:\n",
        "            checkpoint.save(file_prefixx=checkpoint_prefix)"
      ],
      "metadata": {
        "id": "G7aUzfcgNOkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50"
      ],
      "metadata": {
        "id": "g0rn7YAmNQKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "train(train_data,EPOCHS)"
      ],
      "metadata": {
        "id": "DSkW6KN0NQ83"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}